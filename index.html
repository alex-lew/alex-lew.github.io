<!DOCTYPE html>

<html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111705087-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-111705087-1');
  </script>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Personal website for Alex Lew, a PhD student at MIT's Probabilistic Computing Project. Publications, talks, teaching, and projects.">
  <title>Alex Lew | MIT</title>
  <link rel="stylesheet" type="text/css" href="/styles.css">
  <link href="https://fonts.googleapis.com/css?family=Nunito:400,700|Source+Code+Pro" rel="stylesheet">
  <link rel="stylesheet" href="/monokai.css">
  <link rel="stylesheet" href="/tango.css" media="print">
</head>
<body>
<section id="intro">
            <img src="face.jpg" class="face-circle">
            <div class="nobreak"><h1 class="keep-with-next">Alex Lew</h1><p>PhD candidate, <a href="http://probcomp.csail.mit.edu">MIT Probabilsitic Computing Project</a><br/><em>Starting Fall 2025:</em> Assistant Professor, <a href="https://cs.yale.edu">Yale Computer Science</a></p></div><p>Starting Fall 2025, I’m thrilled to be joining Yale’s Computer Science department as an Assistant Professor. Please <a href="yale">get in touch</a> if you might be interested in a PhD or postdoc on probabilistic and differentiable programming!</p>
    </section>
    <section id="homecontent"><div><h1 class="title">Research</h1><p><b>My research aims to automate and scale up principled probabilistic reasoning</b>, in much the same way that tools like <a href="https://tensorflow.org">TensorFlow</a> and <a href="https://pytorch.org">PyTorch</a> have automated and scaled up deep learning. To that end, I develop:</p><ul class="research"><li><b>Theoretical foundations for probabilistic programming:</b> e.g., <a href="https://arxiv.org/abs/2302.10636">new semantic models</a> for reasoning clearly about expressive probabilistic and differentiable programs, <a href="https://dl.acm.org/citation.cfm?id=3371087">a type system</a> for enforcing measure-theoretic correctness properties of inference algorithms, and <a href="https://arxiv.org/abs/2203.02836">a unifying framework</a> for designing Monte Carlo and variational inference algorithms with <a href="https://george.matheos.com/uploads/SMCP3_preprint.pdf">powerful proposal distributions</a>.</li><li><p><b>Probabilistic program compilers that automate and speed up the math behind learning and inference:</b> e.g., <a href="https://dl.acm.org/doi/abs/10.1145/3571198">a new AD algorithm</a> that automatically constructs gradient estimators for optimizing probabilistic objectives, and <a href="https://dl.acm.org/doi/abs/10.1145/3591290">a new compiler</a> for <a href="https://dl.acm.org/citation.cfm?id=3314221.3314642">Gen</a> programs that synthesizes fast, unbiased estimators of probability densities and their reciprocals, for use in Monte Carlo and variational inference.</p><li><b>High-level tools that exploit this automation for scalable probabilistic reasoning in specific domains:</b> e.g., <a href="https://arxiv.org/abs/2007.11838">a data-cleaning system</a> that accurately and efficiently detects and corrects errors in real-world datasets with millions of records, and <a href="https://github.com/probcomp/hfppl">a new domain-specific language</a> for <a href="https://arxiv.org/abs/2306.03081">steering large language models</a> to behave more reliably.</li></li></ul><h1 class="title">Selected Publications</h1><p><em>Selected publications are listed below; please see <a href="https://scholar.google.com/citations?user=TiF1WEsAAAAJ">Google Scholar</a> for a complete list. Asterisks (*) indicate co-first authorship.</em></p><ul class="research"><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://arxiv.org/abs/2406.15742">Probabilistic Programming with Programmable Variational Inference</a></span><br/></div><span>McCoy Becker*, <strong>Alexander Lew*</strong>, Xiaoyan Wang, Matin Ghavami, Mathieu Huot, Martin Rinard, Vikash Mansinghka</span><br/><span class="research-venue">PLDI 2024</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://arxiv.org/abs/2302.10636">ωPAP Semantics: Reasoning Denotationally About Higher-Order, Recursive Probabilistic and Differentiable Programs</a></span><br/></div><span>Mathieu Huot*, <strong>Alexander Lew*</strong>, Vikash Mansinghka, Sam Staton</span><br/><span class="research-venue">LICS 2023, distinguished paper</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://dl.acm.org/doi/abs/10.1145/3591290">Probabilistic Programming with Stochastic Probabilities</a></span><br/></div><span><strong>Alexander Lew</strong>, Matin Ghavami, Martin Rinard, Vikash Mansinghka</span><br/><span class="research-venue">PLDI 2023</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://dl.acm.org/doi/abs/10.1145/3571198">ADEV: Sound Automatic Differentiation of Expected Values of Probabilistic Programs</a></span><br/></div><span><strong>Alexander Lew*</strong>, Mathieu Huot*, Sam Staton, Vikash Mansinghka</span><br/><span class="research-venue">POPL 2023, distinguished paper</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://george.matheos.com/uploads/SMCP3_preprint.pdf">SMCP³: Sequential Monte Carlo with Probabilistic Program Proposals</a></span><br/></div><span><strong>Alexander Lew*</strong>, George Matheos*, Tan Zhi-Xuan, Matin Ghavami, Nishad Gothoskar, Stuart Russell, Vikash Mansinghka</span><br/><span class="research-venue">AISTATS 2023</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://arxiv.org/abs/2203.02836">Recursive Monte Carlo and Variational Inference with Auxiliary Variables</a></span><br/></div><span><strong>Alexander Lew</strong>, Marco Cusumano-Towner, Vikash Mansinghka</span><br/><span class="research-venue">UAI 2022</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="http://proceedings.mlr.press/v130/lew21a">PClean: Bayesian Data Cleaning at Scale with Domain-Specific Probabilistic Programming</a></span><br/></div><span><strong>Alexander Lew</strong>, Monica Agrawal, David Sontag, Vikash Mansinghka</span><br/><span class="research-venue">AISTATS 2021, oral presentation</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://cognitivesciencesociety.org/cogsci20/papers/0520/0520.pdf">Leveraging Unstructured Statistical Knowledge in a Probabilistic Language of Thought</a></span><br/></div><span><strong>Alexander Lew</strong>, Michael Henry Tessler, Vikash Mansinghka, Joshua Tenenbaum</span><br/><span class="research-venue">COGSCI 2020</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://dl.acm.org/citation.cfm?id=3371087">Trace Types and Denotational Semantics for Sound Programmable Inference in Probabilistic Languages</a></span><br/></div><span><strong>Alexander Lew</strong>, Marco Cusumano-Towner, Benjamin Sherman, Michael Carbin, Vikash Mansinghka</span><br/><span class="research-venue">POPL 2020</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://arxiv.org/abs/1904.06317">Few-Shot Bayesian Imitation Learning with Logical Program Policies</a></span><br/></div><span>Tom Silver, Kelsey Allen, <strong>Alexander Lew</strong>, Leslie Kaelbling, Josh Tenenbaum</span><br/><span class="research-venue">AAAI 2020</span></li><li><div class="nobreak"><span class="keep-with-next paper-title"><a href="https://dl.acm.org/citation.cfm?id=3314221.3314642">Gen: A General-Purpose Probabilistic Programming System with Programmable Inference</a></span><br/></div><span>Marco Cusumano-Towner, Feras Saad, <strong>Alexander Lew</strong>, Vikash Mansinghka</span><br/><span class="research-venue">PLDI 2019</span></li></ul></div><div><h1 class="title">Recorded Talks</h1><p>Some of my research talks are available online with video recordings:</p><ul class="bullet-list"><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=7ILj_bx2zRI">Scaling Probabilistic AI via Automatic Differentiation of Probabilistic Programs</a></span><br/></div><span>2024-03-25 / <em style="color:#678">University of Wisconsin - Weekly PL Seminar</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=Uskm9a26V6U">Integrating Language into Intelligent Architectures</a> <span class="talk-extra">(with Lio Wong)</span></span><br/></div><span>2023-08-17 / <em style="color:#678">Simons Institute Workshop on Large Language Models and Transformers</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?app=desktop&amp;v=gejOxeMuJ7M&amp;t=1h36s">Probabilistic Programming with Stochastic Probabilities</a></span><br/></div><span>2023-06-20 / <em style="color:#678">PLDI 2023</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=4ifhXVmV_RM">ADEV: Sound Automatic Differentiation of Expected Values of Probabilistic Programs</a></span><br/></div><span>2023-01-19 / <em style="color:#678">POPL 2023</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=rps5QO_qf8Y">What do the posteriors of probabilistic programs look like?</a></span><br/></div><span>2023-01-15 / <em style="color:#678">Languages for Inference Workshop 2023</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=ZaSFbnMB8SM">Towards Denotational Semantics of AD for Higher-Order, Recursive, Probabilistic Languages</a></span><br/></div><span>2022-01-16 / <em style="color:#678">Languages for Inference Workshop 2022</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://slideslive.com/38971382">Reasoning about AD in Higher-Order, Recursive, Probabilistic Languages</a> <span class="talk-extra">(best talk award)</span></span><br/></div><span>2021-12-13 / <em style="color:#678">NeurIPS Differentiable Programming Workshop 2021</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://slideslive.com/38953394">PClean: Bayesian Data Cleaning at Scale with Domain-Specific Probabilistic Programming</a></span><br/></div><span>2021-04-14 / <em style="color:#678">AISTATS 2021</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=kOYDGkv0PvA">Probabilistic Programming with Correct-by-Construction Densities</a></span><br/></div><span>2021-02-18 / <em style="color:#678">Joint PPS-PIHOC-DIAPASoN Workshop 2021</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://youtu.be/8Ag26RiZEPA">On Automating the Estimation of Radon-Nikodym Derivatives for Probabilistic Programs</a></span><br/></div><span>2021-01-17 / <em style="color:#678">Languages for Inference Workshop 2021</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://vconf_materials.s3.amazonaws.com/boothmaterials/COGSCIPostervideo_xk5ay32j2z.mov">Leveraging Unstructured Statistical Knowledge in a Probabilistic Language of Thought</a></span><br/></div><span>2020-08-03 / <em style="color:#678">COGSCI 2020</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=bxazr1DcuTY">Trace Types and Denotational Semantics for Sound Programmable Inference in Probabilistic Languages</a></span><br/></div><span>2020-01-23 / <em style="color:#678">POPL 2020</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=MiiWzJE0fEA">Probabilistic Scripts for Automating Common-Sense Tasks</a></span><br/></div><span>2019-09-14 / <em style="color:#678">StrangeLoop 2019</em></span></li><li><div class="nobreak"><span class="keep-with-next"><a href="https://www.youtube.com/watch?v=B7mc1wXPZR8">Gen: A General-Purpose Probabilistic Programming System</a> <span class="talk-extra">(delivered in Marco Cusumano-Towner’s stead)</span></span><br/></div><span>2019-07-25 / <em style="color:#678">JuliaCon 2019</em></span></li></ul></div><div><h1 class="title">Teaching</h1><p><b>At MIT</b>, I co-taught a January-term course on <a href="http://student.mit.edu/searchiap/iap-9289afed66a765f3016799a22b7d0acb.html">applied probabilistic programming</a>, and served twice as a TA for <a href="https://www.eecs.mit.edu/academics-admissions/academic-information/subject-updates-spring-2019/6885">6.885: Probabilistic Programming &amp; AI.</a></p><hr/><p><b>From 2015 to 2018</b>, I taught computer science full-time at <a href="http://commschool.org">Commonwealth School.</a></p><ul><li><span><a href="cs1.html">CS 1: Intro to Program Design</a></span></li><li><span><a href="cs2.html">CS 2: AP Computer Science Principles</a></span></li><li><span><a href="cs3.html">CS 3: Data Structures and Algorithms</a></span></li><li><span><a href="cs4.html">CS 4: Advanced Topics in Computer Science</a></span></li></ul><hr/><p><b>From 2015 to 2019</b>, I served as a TA at the <a href="https://strategicplan.duke.edu/initiatives/machine-learning-summer-school/">Duke Machine Learning Summer School</a>.</p><ul><li><span class="keep-with-next"><a href="http://nbviewer.jupyter.org/github/kevinjliang/Duke-Tsinghua-MLSS-2017/blob/master/01B_TensorFlow_Fundamentals.ipynb">TensorFlow fundamentals</a></span></li></ul></div><div><h1 class="title">Contact</h1><p>Email me at alexlew AT mit DOT edu.</p></div></section>

</body>